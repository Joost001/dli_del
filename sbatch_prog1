#!/bin/bash
#SBATCH --partition=gpuq
#SBATCH --qos=gpu
#SBATCH --job-name=jbottenb_dli_del
/home/jbottenb/repositories/nlp_research/dli_del
#SBATCH --output=/home/jbottenb/repositories/nlp_research/dli_del/train_asr.%j.out
#SBATCH --error=/home/jbottenb/repositories/nlp_research/dli_del/train_asr.%j.out
#SBATCH --nodes=4
#SBATCH --ntasks-per-node=4
#SBATCH --gres=gpu:A100.80gb:3
#SBATCH --mem=20G
#SBATCH --export=ALL
#SBATCH --time=0-04:00:00

set echo 
umask 0022 
# to see ID and state of GPUs assigned
nvidia-smi 

## Load the necessary modules
module load gnu10 python cuda

## Execute your script
echo 'Running python program...'

run() {
    python /home/jbottenb/repositories/nlp_research/dli_del/train_asr-by-w2v2-ft.py $1 $2 $3 $4 $5
}

repo_path_or_name=facebook/wav2vec2-large-robust-ft-swbd-300h
output_dir=/home/jbottenb/data/dli_del/
train_tsv=/home/jbottenb/repositories/nlp_research/dli_del_dev001/data/wav_split_gold/train.tsv
eval_tsv=/home/jbottenb/repositories/nlp_research/dli_del_dev001/data/wav_split_gold/eval.tsv
use_target_vocab='--use_target_vocab=False'

source ~/venv/dli_del/bin/activate
run $repo_path_or_name $output_dir $train_tsv $eval_tsv $use_target_vocab
