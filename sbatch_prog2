#!/bin/bash 
#SBATCH --partition=gpuq 
#SBATCH --qos=gpu 
#SBATCH --job-name=jbottenb_dli_del 
#SBATCH --output=fine-tune_w2v2.%j.out 
#SBATCH --error=fine-tune_w2v2.%j.out 
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1 
#SBATCH --gres=gpu:A100.80gb:1 
#SBATCH --mem=8G
#SBATCH --export=ALL 
#SBATCH --time=0-01:00:00 
#
set echo 
umask 0022 
# to see ID and state of GPUs assigned
nvidia-smi 

## Load the necessary modules
module load gnu10
module load python

## Execute your script
run() {
    python /home/jbottenb/repositories/nlp_research/dli_del/train_asr-by-w2v2-ft.py $1 $2 $3 $4 $5
}

repo_path_or_name=facebook/wav2vec2-large-robust-ft-swbd-300h
output_dir=/home/jbottenb/data/dli_del/
train_tsv=/home/jbottenb/repositories/nlp_research/dli_del_dev001/data/wav_split_gold/train.tsv
eval_tsv=/home/jbottenb/repositories/nlp_research/dli_del_dev001/data/wav_split_gold/eval.tsv
use_target_vocab='--use_target_vocab=False'

source ~/venv/dli_del/bin/activate
run $repo_path_or_name $output_dir $train_tsv $eval_tsv $use_target_vocab
